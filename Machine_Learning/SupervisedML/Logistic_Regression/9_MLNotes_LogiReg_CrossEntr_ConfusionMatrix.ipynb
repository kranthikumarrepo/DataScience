{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a34241-88a0-4d25-8c7e-c4e2a4004b0b",
   "metadata": {},
   "source": [
    "#### Cross entropy loss - Loss function of Logistic Regression\n",
    "https://www.youtube.com/watch?v=MztgenIfGgM\n",
    "\n",
    "Mean Square Error is a Loss function used in Linear Regression. This cannot be used in Logistic Regression.\n",
    "\n",
    "Cross Entropy Loss is a Loss function used in Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194da089-7205-4ba7-adb0-5b247061b3e4",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "- Confusion matrix is a simple table used to measure how well a classification model is performing.\n",
    "- It compares the predictions made by the model with the actual results and shows where the model was right or wrong.\n",
    "- This helps you understand where the model is making mistakes so you can improve it.\n",
    "- It breaks down the predictions into four categories:\n",
    "- .\n",
    "- True Positive (TP): The model correctly predicted a positive outcome i.e the actual outcome was positive.\n",
    "- Actual 1 = Predict 1 = True Positive\n",
    "- .\n",
    "- True Negative (TN): The model correctly predicted a negative outcome i.e the actual outcome was negative.\n",
    "- Actual 0 = Predict 0 = True Negative\n",
    "- .\n",
    "- False Positive (FP): The model incorrectly predicted a positive outcome i.e the actual outcome was negative. It is also known as a Type I error\n",
    "- Actual 0 <> Predict 1 = False Positive\n",
    "- .\n",
    "- False Negative (FN): The model incorrectly predicted a negative outcome i.e the actual outcome was positive. It is also known as a Type II error.\n",
    "- Actual 1 <> Predict 0 = False Negative\n",
    "- .\n",
    "- Note:\n",
    "- True/False is always with respect to the predicted value. True means that the values were accurately predicted, False means that there was an error or wrong prediction.\n",
    "- The rows represent the actual classes the outcomes should have been. While the columns represent the predictions we have made. Using this table it is easy to see which predictions are wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f11fad5d-ea6e-4474-a5b9-666fa52bcd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 19,  89],\n",
       "       [ 83, 809]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "\n",
    "actual = numpy.random.binomial(1,.9,size = 1000)\n",
    "predicted = numpy.random.binomial(1,.9,size = 1000) # We can use my_model.predict(x_test) in real time.\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e469ecf-d531-42f5-aea5-df4e9e6b8d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19,  89],\n",
       "       [ 83, 809]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix without graphs\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f3c7e619-a1e6-4ff5-9c21-5bf383f53b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN =  19\n",
      "FP =  89\n",
      "FN =  83\n",
      "TP =  809\n"
     ]
    }
   ],
   "source": [
    "# To understand the above matrix, use ravel() method\n",
    "\n",
    "from sklearn import metrics\n",
    "TN, FP, FN, TP = metrics.confusion_matrix(actual, predicted).ravel()\n",
    "print(\"TN = \", TN)\n",
    "print(\"FP = \", FP)\n",
    "print(\"FN = \", FN)\n",
    "print(\"TP = \", TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a92140e-d1e9-4eb5-9600-023fd9936eec",
   "metadata": {},
   "source": [
    "#### Above result explained\n",
    "\n",
    "- True Negative (Top-Left Quadrant)\n",
    "- False Positive (Top-Right Quadrant)\n",
    "- False Negative (Bottom-Left Quadrant)\n",
    "- True Positive (Bottom-Right Quadrant)\n",
    "- Note:- True means that the values were accurately predicted, False means that there was an error or wrong prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e74bd-558e-4b7e-9317-db5164dd32a5",
   "metadata": {},
   "source": [
    "### From Consufion Matrix we can calculate different measures to quantify the quality of the model.\n",
    "- The matrix provides us with many useful metrics that help us to evaluate our classification model.\n",
    "- The different measures include: Accuracy, Precision, Sensitivity (Recall), Specificity, and the F-score, explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9309c71-726a-4a8b-9430-c7bdf316ea12",
   "metadata": {},
   "source": [
    "#### 1. Accuracy\n",
    "- Accuracy measures how often the model is correct.\n",
    "- Total correct outcomes / all the outcomes.\n",
    "- (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "28838d94-b50e-43c6-8932-539b5a5dadf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.828"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Accuracy = accuracy_score(actual, predicted)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006eb7b-d1da-4013-8279-488a70e1067c",
   "metadata": {},
   "source": [
    "#### 2. Precision\n",
    "- Focus is only on Positive.\n",
    "- Of the positives predicted, what percentage is truly positive?\n",
    "- Precision does not evaluate the correctly predicted negative cases.\n",
    "- (TP)/(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0d3992a4-aa36-4023-9560-30379962ace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008908685968819"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "Precision = precision_score(actual, predicted)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa1bc4-936f-48c0-bb19-c5f3d8d45dde",
   "metadata": {},
   "source": [
    "#### 3. False Positive Ratio - FPR \n",
    "- The proportion of actual negative instances that are incorrectly classified as positive.\n",
    "- A lower FPR is generally desirable, as it indicates a more specific model that is less prone to misclassifying negative cases as positive. \n",
    "- FP / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9f991f99-f5ab-4fac-9963-6e060f205334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8240740740740741"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "TN, FP, FN, TP = metrics.confusion_matrix(actual, predicted).ravel()\n",
    "FPR = FP / (TN + FP)\n",
    "FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60939f-ac9b-4005-ba89-3e9aeeda3d04",
   "metadata": {},
   "source": [
    "#### 4. Sensitivity (Recall) - True Positive Ratio(TPR)\n",
    "- Sensitivity (sometimes called Recall) measures how good the model is at predicting positives.\n",
    "- Sensitivity is good at understanding how well the model predicts something is positive. From prespective of Positive results.\n",
    "- Of all the positive cases, what percentage are predicted correctly positive?\n",
    "- This means it looks at true positives and false negatives (which are positives that have been incorrectly predicted as negative).\n",
    "- TP / (TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "205b6c8d-e1c4-42aa-aa37-c77ffccb56fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9069506726457399"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "Sensitivity_recall = recall_score(actual, predicted)\n",
    "Sensitivity_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0605af7-6b99-42d7-8fcf-f29e7c18e7ea",
   "metadata": {},
   "source": [
    "#### 5. Specificity - True negative ratio\n",
    "- Specificity is good at understanding how well the model is at prediciting negative results?\n",
    "- Specificity is similar to sensitivity, but looks at it from the persepctive of negative results.\n",
    "- TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3b1b2de0-392f-407e-a0b6-4dea070eaa7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17592592592592593"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since it is just the opposite of Recall, we use the recall_score function, taking the opposite position label.\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "Specificity = metrics.recall_score(actual, predicted, pos_label=0)\n",
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9918b3c-9f04-485a-880a-1b14e865069f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Or use the manual derivation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 4\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m confusion_matrix(actual, predicted)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m      5\u001b[0m specificity \u001b[38;5;241m=\u001b[39m tn \u001b[38;5;241m/\u001b[39m (tn \u001b[38;5;241m+\u001b[39m fp)\n\u001b[0;32m      6\u001b[0m specificity\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actual' is not defined"
     ]
    }
   ],
   "source": [
    "# Or use the manual derivation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(actual, predicted).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9216e1b-35ab-4d08-b3c1-be5df9d435e1",
   "metadata": {},
   "source": [
    "#### 6. F1 Score\n",
    "- F-score is the \"harmonic mean\" of precision and sensitivity.\n",
    "- It considers both false positive and false negative cases and is good for imbalanced datasets.\n",
    "- This score does not take into consideration the True Negative values.\n",
    "- 2 * ((Precision * Sensitivity) / (Precision + Sensitivity))\n",
    "- or ???? check and confirm\n",
    "- (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "95ede954-f507-47c7-afd1-79f09cd13041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9039106145251397"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1_score = f1_score(actual, predicted)\n",
    "F1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c704e6-f922-4d32-9013-5038d0c37468",
   "metadata": {},
   "source": [
    "#### 7. ROC AUC Curve\n",
    "\n",
    "https://www.w3schools.com/python/python_ml_auc_roc.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eba2f7-da32-4259-a133-3eff12c7ee00",
   "metadata": {},
   "source": [
    "AUC curve value close to 1 is a better model\n",
    "\n",
    "this can be calculated on any type of model, Linear R, Logistic Regre, etc.\n",
    "\n",
    "Used to determine the best threshold and how we want the TPR/FPR/etc.\n",
    "\n",
    "Where are we giving the threshold value\n",
    "\n",
    "what does below parameters signify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9505405a-c9ed-4dcf-8271-66e942996883",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[1;32m----> 3\u001b[0m roc_curve(y_test,y_predict)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "roc_curve(y_test,y_predict)\n",
    "#fpr - false positive rate\n",
    "#tpr - true positive rate\n",
    "# threshold value\n",
    "#(array([0., 1.]), array([0., 1.]), array([inf,  0.]))\n",
    "#FPR/TPR/Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08b7fd-9a63-415e-b1d4-ff43ef8d0c86",
   "metadata": {},
   "source": [
    "#### roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4b1cd5c5-ceb4-4941-9dcb-8861e6adf3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test,y_predict)\n",
    "#fpr,tpr,threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b45746a7-298c-4947-8260-02fd79cad93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        47\n",
      "   macro avg       1.00      1.00      1.00        47\n",
      "weighted avg       1.00      1.00      1.00        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d4d07-6722-486e-8b2a-30e04d0369cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
